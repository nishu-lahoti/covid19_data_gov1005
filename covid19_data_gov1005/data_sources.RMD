---
title: "Data Sources for Covid-19 Project"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(dplyr)
library(readr)
library(rvest)
library(janitor)
library(skimr)
library(sf)
library(maps)
library(tibble)
library(countrycode)
library(rworldmap)
library(gganimate)
library(chron)
library(date)
library(stringr)
library(readxl)
library(date)
library(chron)

options(scipen = 999)
```

```{r Spread, echo=FALSE}

# Import NYTimes Data

us_states <- read.csv(url("https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv"))
us_counties <- read.csv(url("https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv"))

saveRDS(us_states, file = "../team_data/nytimes_states.RDS")
saveRDS(us_counties, file = "../team_data/nytimes_counties.RDS")


# Import & Clean Johns Hopkins Data

us_confirmed <- read.csv(url("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_US.csv")) %>% 
  clean_names() %>%
  pivot_longer(cols = c(x1_22_20:x4_15_20), names_to = "date", values_to = "confirmed") %>%
  select(combined_key, date, confirmed)

us_deaths <- read.csv(url("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_US.csv")) %>% 
  clean_names() %>%
  pivot_longer(cols = c(x1_22_20:x4_15_20), names_to = "date", values_to = "deaths") %>%
  select(combined_key, date, deaths)

global_confirmed <- read.csv(url("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv")) %>% 
  clean_names() %>%
  pivot_longer(cols = c(x1_22_20:x4_15_20), names_to = "date", values_to = "confirmed") %>%
  select(country_region, date, confirmed)

global_deaths <- read.csv(url("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv")) %>% 
  clean_names() %>%
  pivot_longer(cols = c(x1_22_20:x4_15_20), names_to = "date", values_to = "deaths") %>%
  select(country_region, date, deaths)

global_recovered <- read.csv(url("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_recovered_global.csv")) %>% 
  clean_names() %>%
  pivot_longer(cols = c(x1_22_20:x4_15_20), names_to = "date", values_to = "recovered") %>%
  select(country_region, date, recovered)

# global_recovered_2 <- read.csv(url("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_recovered_global.csv")) %>%
#   clean_names() %>%
#   pivot_longer(cols = -c(province_state, country_region, lat, long), names_to = "date",
#                values_to = "confirmed")

us_daily_reports <- read.csv(url("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports_us/04-17-2020.csv")) %>% clean_names()


# Webscrape Worldometer Data

worldometer_url <- paste0("https://www.worldometers.info/coronavirus/")
worldometer_html <- read_html(worldometer_url)
worldometer <- worldometer_html %>% 
               html_nodes("table")
worldometer <- worldometer[[1]] %>% html_table
worldometer <- worldometer %>% clean_names()

# Clean worldometer data, changing column types to reflect numbers where
# necessary.

worldometer <- worldometer %>%
  mutate(total_cases = parse_number(total_cases),
         new_cases = parse_number(new_cases),
         total_deaths = parse_number(total_deaths),
         new_deaths = parse_number(new_deaths),
         total_recovered = parse_number(total_recovered),
         active_cases = parse_number(active_cases),
         serious_critical = parse_number(serious_critical),
         total_tests = parse_number(total_tests),
         tests_1m_pop = parse_number(tests_1m_pop)) %>%
  filter(! country_other %in% c("World", "Total:", "Europe", "North America", "Asia", "South America",
                                "Africa", "Oceania", "")) %>%
  arrange(desc(total_cases))

saveRDS(worldometer, file = "worldometer.RDS")
```

```{r Spread with Increments, echo=FALSE}

# Updating the date and creating an increment column for the confirmed cases in
# the US.

confirmedCovidUS <- us_confirmed %>%
  mutate(sep_date = sub(".", "", date)) %>%
  mutate(new_date = as.Date(sep_date, format = "%m_%d_%y")) %>%
  select(combined_key, new_date, confirmed)

confirmedCovidUS <- confirmedCovidUS %>%
  mutate(helper = c(confirmedCovidUS$confirmed[1], confirmedCovidUS$confirmed[1:(nrow(confirmedCovidUS)-1)])) %>%
  mutate(increment = confirmed - helper) %>%
  group_by(combined_key)

# Updating the date and creating an increment column for the confirmed cases in
# the US.

deathsCovidUS <- us_deaths %>%
  mutate(sep_date = sub(".", "", date)) %>%
  mutate(new_date = as.Date(sep_date, format = "%m_%d_%y")) %>%
  select(combined_key, new_date, deaths)

deathsCovidUS <- deathsCovidUS %>%
  mutate(helper = c(deathsCovidUS$deaths[1], deathsCovidUS$deaths[1:(nrow(deathsCovidUS)-1)])) %>%
  mutate(increment = deaths - helper) %>%
  group_by(combined_key)

# Updating the date and creating an increment column for the confirmed cases
# across the globe

confirmedCovidGlobal <- global_confirmed %>%
  mutate(sep_date = sub(".", "", date)) %>%
  mutate(new_date = as.Date(sep_date, format = "%m_%d_%y")) %>%
  select(country_region, new_date, confirmed)

confirmedCovidGlobal <- confirmedCovidGlobal %>%
  mutate(helper = c(confirmedCovidGlobal$confirmed[1],
                    confirmedCovidGlobal$confirmed[1:(nrow(confirmedCovidGlobal)-1)])) %>%
  mutate(increment = confirmed - helper) %>%
  group_by(country_region)

# Updating the date and creating an increment column for the deaths  across the
# globe

deathsCovidGlobal <- global_deaths %>%
  mutate(sep_date = sub(".", "", date)) %>%
  mutate(new_date = as.Date(sep_date, format = "%m_%d_%y")) %>%
  select(country_region, new_date, deaths)

deathsCovidGlobal <- deathsCovidGlobal %>%
  mutate(helper = c(deathsCovidGlobal$deaths[1],
                    deathsCovidGlobal$deaths[1:(nrow(deathsCovidGlobal)-1)])) %>%
  mutate(increment = deaths - helper) %>%
  group_by(country_region)

# Updating the date and creating an increment column for the recovered cases
# across the globe

recoveredCovidGlobal <- global_recovered %>%
  mutate(sep_date = sub(".", "", date)) %>%
  mutate(new_date = as.Date(sep_date, format = "%m_%d_%y")) %>%
  select(country_region, new_date, recovered)

recoveredCovidGlobal <- recoveredCovidGlobal %>%
  mutate(helper = c(recoveredCovidGlobal$recovered[1],
                    recoveredCovidGlobal$recovered[1:(nrow(recoveredCovidGlobal)-1)])) %>%
  mutate(increment = recovered - helper) %>%
  group_by(country_region)

# Joined Data US & Global

covidUS <- confirmedCovidUS %>%
  inner_join(deathsCovidUS, by = c("combined_key", "new_date"), suffix = c("_confirmed", "_deaths")) %>%
  select(combined_key, new_date, confirmed, increment_confirmed, deaths, increment_deaths)

covidGlobal <- confirmedCovidGlobal %>%
  inner_join(deathsCovidGlobal, by = c("country_region", "new_date"), suffix = c("_confirmed", "_deaths")) %>%
  inner_join(recoveredCovidGlobal, by = c("country_region", "new_date"), suffix = c("_confirmed", "_recovered")) %>%
  select(country_region, new_date, confirmed, increment_confirmed, deaths, increment_deaths, recovered, increment)

# Johns Hopkins US Daily Report. Used to gather testing rates by State.

testing_by_state <- us_daily_reports %>%
  filter(!is.na(people_tested))

# Saving files for team use

saveRDS(covidUS, file = "covidUS.RDS")
saveRDS(covidGlobal, file = "covidGlobal.RDS")
saveRDS(testing_by_state, file = "tests_per_state.RDS")
```

```{r Policy, echo=FALSE}

# Import Oxford Covid-19 Data

oxford <- read.csv(url("https://raw.githubusercontent.com/OxCGRT/covid-policy-tracker/master/data/OxCGRT_latest.csv")) %>% 
  mutate(new_date = as.Date(as.character(Date), format = "%Y%m%d"))


# Import & Clean JHU CSSE Data (unlike Spread, no increments here), starting
# with Confirmed

global_confirmed <- read.csv(url("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv")) %>% 
  clean_names() %>% 
  pivot_longer(cols = -c(province_state, country_region, lat, long), names_to = "date", values_to = "confirmed") %>%
  select(country_region, date, confirmed)

global_confirmed <- global_confirmed %>% 
  mutate(sep_date = sub("x", "", date)) %>%
  mutate(new_date = as.Date(sep_date, format = "%m_%d_%y")) %>%
  group_by(country_region, new_date) %>%
  summarize(confirmed = sum(confirmed)) 

# JHU Deaths

global_deaths <- read.csv(url("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv")) %>% 
  clean_names() %>%
  pivot_longer(cols = -c(province_state, country_region, lat, long), names_to = "date", values_to = "deaths") %>%
  select(country_region, date, deaths) 

global_deaths <- global_deaths %>% 
  mutate(sep_date = sub("x", "", date)) %>%
  mutate(new_date = as.Date(sep_date, format = "%m_%d_%y")) %>%
  group_by(country_region, new_date) %>%
  summarize(deaths = sum(deaths)) 

# JHU Recovered

global_recovered <- read.csv(url("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_recovered_global.csv")) %>% 
  clean_names() %>%
  pivot_longer(cols = -c(province_state, country_region, lat, long), names_to = "date", values_to = "recovered") %>%
  select(country_region, date, recovered)

global_recovered <- global_recovered %>% 
  mutate(sep_date = sub("x", "", date)) %>%
  mutate(new_date = as.Date(sep_date, format = "%m_%d_%y")) %>%
  group_by(country_region, new_date) %>%
  summarize(recovered = sum(recovered))

# Join JHU data 

covidGlobal <- global_confirmed %>%
  inner_join(
    global_deaths, 
    by = c("country_region", "new_date"), 
    suffix = c("_confirmed", "_deaths")
  ) %>%
  inner_join(
    global_recovered, 
    by = c("country_region", "new_date"), 
    suffix = c("_confirmed", "_recovered")
  ) %>%
  select(
    country_region, 
    new_date, 
    confirmed, 
    deaths, 
    recovered
  ) %>% 
  rename(
    Country = country_region
  )

# Use countrycode package to standardize all country names, for easy joining
# with Oxford data (which comes with CountryCode column). Filtering out 2 cruise
# ships, which are not of interest in our analysis.

covidGlobal <- covidGlobal %>% 
  mutate(CountryCode = countrycode(Country, origin = 'country.name', destination = 'iso3c')) %>% 
  filter(Country != "Diamond Princess", Country != "MS Zaandam")


# Join Oxford and JHU Data

stringency <- oxford %>% 
  full_join(covidGlobal, by = c("CountryCode", "new_date")) %>% 
  filter(!is.na(confirmed)) %>% 
  select(
    Country, 
    CountryCode, 
    new_date, 
    S1_School.closing,
    S1_IsGeneral,
    S2_Workplace.closing,
    S2_IsGeneral,
    S3_Cancel.public.events,
    S3_IsGeneral,
    S4_Close.public.transport,
    S4_IsGeneral,
    S5_Public.information.campaigns,
    S5_IsGeneral,
    S6_Restrictions.on.internal.movement,
    S6_IsGeneral,
    S7_International.travel.controls,
    S8_Fiscal.measures,
    S9_Monetary.measures,
    S10_Emergency.investment.in.health.care,
    S11_Investment.in.Vaccines,
    S12_Testing.framework,
    S13_Contact.tracing,
    StringencyIndexForDisplay,
    confirmed,
    deaths,
    recovered
    )

# Importing Region and Subregion Lists

regions <- read.csv(url("https://raw.githubusercontent.com/lukes/ISO-3166-Countries-with-Regional-Codes/master/all/all.csv")) %>% 
  select(name, region, sub.region) %>% 
  rename(Country = name)

# Joining with existing dataset

stringency_regions <- stringency %>% 
  full_join(regions, by = "Country")
```

```{r Static Data, echo=FALSE}

# Import population and GDP data from World Bank, latest available 2018

population_data_18 <- read_csv("../gdp/API_pop.csv", skip = 3) %>% 
  clean_names() %>% 
 select(country_code, x2018) %>% 
  rename(pop_2018 = x2018)

gdp_data_18 <- read_csv("../gdp/API_gdp.csv", skip = 3) %>%
  clean_names() %>% 
  select(country_code, x2018) %>% 
  rename(gdp_2018 = x2018)

# Combine to create variable for GDP per capita

gdp_pop_2018 <- gdp_data_18 %>% 
  left_join(population_data_18, by = "country_code") %>% 
  mutate(gdp_per_capita = round(gdp_2018 / pop_2018, digits = 2))


# Create final dataset for POLICY, adding per capita and per case variables and
# log transformation (log base 10)

policy <- stringency_regions %>% 
  full_join(population_data_18, by = c("CountryCode" = "country_code")) %>% 
  mutate(confirmed_per_capita = confirmed / pop_2018,
         deaths_per_confirmed = deaths / confirmed,
         recovered_per_confirmed = recovered / confirmed) %>% 
  mutate(log_confirmed = log10(confirmed), 
         log_deaths = log10(deaths),
         log_recovered = log10(recovered))

# Saving files for team use
saveRDS(gdp_pop_2018, file = "gdp_per_capita.RDS")
saveRDS(policy, file = "policy.RDS")
```

```{r Economic Impact, echo=FALSE}

# Function to take stock indices from yahoo and scrape data every time its run
# (updated daily)

stock <- function(url) {
  stock_source <- paste0(url)
  stock_html <- read_html(stock_source)
  stock_data <- stock_html %>% 
    html_nodes("table")
  stock_data <- stock_data[[1]] %>% 
    html_table
  stock_data <- stock_data %>% 
    clean_names() %>% 
    select(date, close)
}

# Korea

kospi <- stock("https://finance.yahoo.com/quote/%5EKS11/history?p=%5EKS11") %>% 
  rename(KOSPI = close)
kospi$date <- as.Date(kospi$date, format = "%B %d,%Y") 

# USA

nasdaq <- stock("https://finance.yahoo.com/quote/%5EIXIC/history?p=%5EIXIC") %>% 
  rename(NASDAQ = close)
nasdaq$date <- as.Date(nasdaq$date, format = "%B %d,%Y") 

# World

msci <- stock("https://finance.yahoo.com/quote/MSCI/history?p=MSCI") %>% 
  rename(MSCI = close)
msci$date <- as.Date(msci$date, format = "%B %d,%Y") 

# China

sse_china <- stock("https://finance.yahoo.com/quote/000001.SS/history?p=000001.SS") %>% 
  rename(SSE_China = close)
sse_china$date <- as.Date(sse_china$date, format = "%B %d,%Y") 

# Europe as a whole

dax <- stock("https://finance.yahoo.com/quote/%5EGDAXI/history?p=%5EGDAXI") %>% 
  rename(DAX = close)
dax$date <- as.Date(dax$date, format = "%B %d,%Y") 

# Italy

ftse_italy <- stock("https://finance.yahoo.com/quote/%5EFTSE%3FP%3DFTSE/history/") %>% 
  rename(FTSE_Italy = close)
ftse_italy$date <- as.Date(ftse_italy$date, format = "%B %d,%Y") 

# Spain

ibex_spain <- stock("https://finance.yahoo.com/quote/%5EIBEX/history?p=%5EIBEX") %>% 
  rename(IBEX_Spain = close)
ibex_spain$date <- as.Date(ibex_spain$date, format = "%B %d,%Y") 

# Willing to add more countries here. Perhaps France/Germany? Iran? Singapore? 

stock_data <- kospi %>% 
  left_join(nasdaq, by = "date", na.rm = TRUE) %>% 
  left_join(msci, by = "date", na.rm = TRUE) %>% 
  left_join(sse_china, by = "date", na.rm = TRUE) %>% 
  left_join(dax, by = "date", na.rm = TRUE) %>% 
  left_join(ftse_italy, by = "date", na.rm = TRUE) %>% 
  left_join(ibex_spain, by = "date", na.rm = TRUE) 
stock_data$KOSPI <- gsub(',', '', stock_data$KOSPI) %>% as.numeric(stock_data$KOSPI)
stock_data$NASDAQ <- gsub(',', '', stock_data$NASDAQ) %>% as.numeric(stock_data$NASDAQ)
stock_data$MSCI <- gsub(',', '', stock_data$MSCI) %>% as.numeric(stock_data$MSCI)
stock_data$SSE_China <- gsub(',', '', stock_data$SSE_China) %>% as.numeric(stock_data$SSE_China)
stock_data$DAX <- gsub(',', '', stock_data$DAX) %>% as.numeric(stock_data$DAX)
stock_data$FTSE_Italy <- gsub(',', '', stock_data$FTSE_Italy) %>% as.numeric(stock_data$FTSE_Italy)
stock_data$IBEX_Spain <- gsub(',', '', stock_data$IBEX_Spain) %>% as.numeric(stock_data$IBEX_Spain)

covid_global_stock <- covidGlobal %>% 
  full_join(stock_data, by = c("new_date" = "date")) %>% 
  select(Country, new_date, confirmed, deaths, recovered, KOSPI, NASDAQ, MSCI, SSE_China, DAX, FTSE_Italy, IBEX_Spain)

saveRDS(covid_global_stock, file = "stock_data.RDS")
```


